{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "# Analytics with Synapse Link and Delta Lake\n",
    "\n",
    "This notebook covers setting up and using analytics capabilities:\n",
    "\n",
    "- **Azure Synapse Link for Cosmos DB** - Real-time analytics without ETL\n",
    "- **Delta Lake Medallion Architecture** - Bronze/Silver data layers\n",
    "- **SQL Serverless Queries** - Query data with T-SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "## Configuration\n",
    "\n",
    "Configure your Azure resources below. Resources can be in **different resource groups** - specify the appropriate resource group for each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION - UPDATE THESE VALUES\n",
    "# ============================================\n",
    "\n",
    "$SUBSCRIPTION_ID = \"363ef5d1-0e77-4594-a530-f51af23dbf8c\"\n",
    "\n",
    "# Resource Groups (can be different for each resource)\n",
    "$COSMOS_RESOURCE_GROUP = \"rg-dlz-cosmosdb-east2-sandbox\"\n",
    "$SYNAPSE_RESOURCE_GROUP = \"rg-sandbox-demo-east2\"\n",
    "$STORAGE_RESOURCE_GROUP = \"rg-dlz-aiml-stack-dev\"\n",
    "\n",
    "# Cosmos DB\n",
    "$COSMOS_ACCOUNT = \"cosmosdb-dlz-east2-sandbox\"\n",
    "$COSMOS_DATABASE = \"DocumentsDB\"\n",
    "$COSMOS_CONTAINER = \"ExtractedDocuments\"\n",
    "\n",
    "# Synapse Analytics\n",
    "$SYNAPSE_WORKSPACE = \"synapse-sandbox-east2-dlz\"\n",
    "\n",
    "# Storage\n",
    "$STORAGE_ACCOUNT = \"aimldatastore\"\n",
    "\n",
    "# ============================================\n",
    "\n",
    "az account set --subscription $SUBSCRIPTION_ID\n",
    "\n",
    "Write-Host \"Configuration set\" -ForegroundColor Green\n",
    "Write-Host \"\"\n",
    "Write-Host \"Resource Groups:\" -ForegroundColor Cyan\n",
    "Write-Host \"  Cosmos DB: $COSMOS_RESOURCE_GROUP\"\n",
    "Write-Host \"  Synapse:   $SYNAPSE_RESOURCE_GROUP\"\n",
    "Write-Host \"  Storage:   $STORAGE_RESOURCE_GROUP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language_info": {
     "name": "polyglot-notebook"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [],
   "source": [
    "# Validate resource access across resource groups\n",
    "Write-Host \"Validating resource access...\" -ForegroundColor Cyan\n",
    "$errors = @()\n",
    "\n",
    "# Check Cosmos DB\n",
    "Write-Host \"`nChecking Cosmos DB...\" -ForegroundColor Gray\n",
    "$cosmosCheck = az cosmosdb show --name $COSMOS_ACCOUNT --resource-group $COSMOS_RESOURCE_GROUP --query \"name\" -o tsv 2>&1\n",
    "if ($LASTEXITCODE -eq 0) {\n",
    "    Write-Host \"  ✓ Cosmos DB: $COSMOS_ACCOUNT\" -ForegroundColor Green\n",
    "} else {\n",
    "    Write-Host \"  ✗ Cosmos DB: $COSMOS_ACCOUNT not found in $COSMOS_RESOURCE_GROUP\" -ForegroundColor Red\n",
    "    $errors += \"Cosmos DB\"\n",
    "}\n",
    "\n",
    "# Check Synapse Workspace\n",
    "Write-Host \"Checking Synapse Workspace...\" -ForegroundColor Gray\n",
    "$synapseCheck = az synapse workspace show --name $SYNAPSE_WORKSPACE --resource-group $SYNAPSE_RESOURCE_GROUP --query \"name\" -o tsv 2>&1\n",
    "if ($LASTEXITCODE -eq 0) {\n",
    "    Write-Host \"  ✓ Synapse: $SYNAPSE_WORKSPACE\" -ForegroundColor Green\n",
    "} else {\n",
    "    Write-Host \"  ✗ Synapse: $SYNAPSE_WORKSPACE not found in $SYNAPSE_RESOURCE_GROUP\" -ForegroundColor Red\n",
    "    $errors += \"Synapse\"\n",
    "}\n",
    "\n",
    "# Check Storage Account\n",
    "Write-Host \"Checking Storage Account...\" -ForegroundColor Gray\n",
    "$storageCheck = az storage account show --name $STORAGE_ACCOUNT --resource-group $STORAGE_RESOURCE_GROUP --query \"name\" -o tsv 2>&1\n",
    "if ($LASTEXITCODE -eq 0) {\n",
    "    Write-Host \"  ✓ Storage: $STORAGE_ACCOUNT\" -ForegroundColor Green\n",
    "} else {\n",
    "    Write-Host \"  ✗ Storage: $STORAGE_ACCOUNT not found in $STORAGE_RESOURCE_GROUP\" -ForegroundColor Red\n",
    "    $errors += \"Storage\"\n",
    "}\n",
    "\n",
    "# Summary\n",
    "if ($errors.Count -eq 0) {\n",
    "    Write-Host \"`n✓ All resources validated successfully\" -ForegroundColor Green\n",
    "} else {\n",
    "    Write-Host \"`n✗ Failed to access: $($errors -join ', ')\" -ForegroundColor Red\n",
    "    Write-Host \"Verify resource names and resource groups are correct\" -ForegroundColor Yellow\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "## 1. Azure Synapse Link for Cosmos DB\n",
    "\n",
    "Synapse Link enables hybrid transactional and analytical processing (HTAP) by automatically syncing operational data to an analytical store.\n",
    "\n",
    "### Benefits\n",
    "- **No ETL Required** - Data automatically syncs (2-5 minute latency)\n",
    "- **No Impact on Transactions** - Analytics run against analytical store\n",
    "- **Cost-Effective** - Pay only for analytical storage consumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [],
   "source": [
    "# Check if Synapse Link is enabled on Cosmos DB account\n",
    "Write-Host \"Checking Synapse Link status...\" -ForegroundColor Cyan\n",
    "\n",
    "$cosmosAccount = az cosmosdb show `\n",
    "    --name $COSMOS_ACCOUNT `\n",
    "    --resource-group $COSMOS_RESOURCE_GROUP `\n",
    "    --query \"{Name:name, SynapseLink:enableAnalyticalStorage}\" `\n",
    "    --output json | ConvertFrom-Json\n",
    "\n",
    "Write-Host \"`nCosmos DB Account: $($cosmosAccount.Name)\"\n",
    "Write-Host \"Resource Group: $COSMOS_RESOURCE_GROUP\"\n",
    "\n",
    "if ($cosmosAccount.SynapseLink -eq $true) {\n",
    "    Write-Host \"Synapse Link: ENABLED\" -ForegroundColor Green\n",
    "} else {\n",
    "    Write-Host \"Synapse Link: DISABLED\" -ForegroundColor Yellow\n",
    "    Write-Host \"Enable via Azure Portal: Cosmos DB > Azure Synapse Link > Enable\" -ForegroundColor Yellow\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [],
   "source": [
    "# Check container analytical store settings\n",
    "Write-Host \"Checking container analytical store...\" -ForegroundColor Cyan\n",
    "\n",
    "$container = az cosmosdb sql container show `\n",
    "    --account-name $COSMOS_ACCOUNT `\n",
    "    --database-name $COSMOS_DATABASE `\n",
    "    --name $COSMOS_CONTAINER `\n",
    "    --resource-group $COSMOS_RESOURCE_GROUP `\n",
    "    --query \"resource.analyticalStorageTtl\" `\n",
    "    --output tsv\n",
    "\n",
    "if ($container -eq \"-1\") {\n",
    "    Write-Host \"Analytical Store: ENABLED (infinite retention)\" -ForegroundColor Green\n",
    "} elseif ($container -gt 0) {\n",
    "    Write-Host \"Analytical Store: ENABLED (TTL: $container seconds)\" -ForegroundColor Green\n",
    "} else {\n",
    "    Write-Host \"Analytical Store: DISABLED\" -ForegroundColor Yellow\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [],
   "source": [
    "# Enable Synapse Link on Cosmos DB account (if not enabled)\n",
    "Write-Host \"Enabling Synapse Link on Cosmos DB account...\" -ForegroundColor Cyan\n",
    "Write-Host \"NOTE: This operation cannot be reversed!\" -ForegroundColor Yellow\n",
    "\n",
    "# Uncomment to enable:\n",
    "az cosmosdb update `\n",
    "    --name $COSMOS_ACCOUNT `\n",
    "    --resource-group $COSMOS_RESOURCE_GROUP `\n",
    "    --enable-analytical-storage true\n",
    "\n",
    "Write-Host \"Uncomment the command above to enable Synapse Link\" -ForegroundColor Yellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "## 2. Synapse Spark Notebooks\n",
    "\n",
    "Query Cosmos DB analytical store using Spark in Synapse Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [],
   "source": [
    "# List Synapse notebooks\n",
    "Write-Host \"Synapse notebooks in workspace:\" -ForegroundColor Cyan\n",
    "\n",
    "az synapse notebook list `\n",
    "    --workspace-name $SYNAPSE_WORKSPACE `\n",
    "    --query \"[].name\" `\n",
    "    --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "### Sample Spark Code for Synapse Notebooks\n",
    "\n",
    "Use this code in Synapse Studio Spark notebooks:\n",
    "\n",
    "```python\n",
    "# Read from Cosmos DB analytical store\n",
    "df = spark.read \\\n",
    "    .format(\"cosmos.olap\") \\\n",
    "    .option(\"spark.synapse.linkedService\", \"LS_CosmosDB\") \\\n",
    "    .option(\"spark.cosmos.container\", \"ExtractedDocuments\") \\\n",
    "    .load()\n",
    "\n",
    "# Run analytics\n",
    "df.createOrReplaceTempView(\"documents\")\n",
    "\n",
    "# Count by model\n",
    "spark.sql(\"\"\"\n",
    "    SELECT modelId, COUNT(*) as count, AVG(modelConfidence) as avg_conf\n",
    "    FROM documents\n",
    "    GROUP BY modelId\n",
    "\"\"\").show()\n",
    "\n",
    "# Recent processing activity\n",
    "spark.sql(\"\"\"\n",
    "    SELECT sourceFile, processedAt, status, modelConfidence\n",
    "    FROM documents\n",
    "    WHERE processedAt > date_sub(current_timestamp(), 7)\n",
    "    ORDER BY processedAt DESC\n",
    "    LIMIT 20\n",
    "\"\"\").show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "## 3. Delta Lake Medallion Architecture\n",
    "\n",
    "Transform data from Cosmos DB into Delta Lake layers:\n",
    "\n",
    "| Layer | Description | Location |\n",
    "|-------|-------------|----------|\n",
    "| **Bronze** | Raw data with ingestion metadata | `delta/bronze/extracted_documents/` |\n",
    "| **Silver** | Cleaned, flattened, partitioned data | `delta/silver/documents/` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "### Sample Bronze Layer Code\n",
    "\n",
    "```python\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import current_timestamp, lit\n",
    "\n",
    "# Read from Cosmos DB analytical store\n",
    "df_cosmos = spark.read \\\n",
    "    .format(\"cosmos.olap\") \\\n",
    "    .option(\"spark.synapse.linkedService\", \"LS_CosmosDB\") \\\n",
    "    .option(\"spark.cosmos.container\", \"ExtractedDocuments\") \\\n",
    "    .load()\n",
    "\n",
    "# Add ingestion metadata\n",
    "df_bronze = df_cosmos \\\n",
    "    .withColumn(\"_ingested_at\", current_timestamp()) \\\n",
    "    .withColumn(\"_source\", lit(\"cosmos_analytical_store\"))\n",
    "\n",
    "# Write to Bronze layer\n",
    "bronze_path = f\"abfss://delta@{storage_account}.dfs.core.windows.net/bronze/extracted_documents/\"\n",
    "\n",
    "df_bronze.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(bronze_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "### Sample Silver Layer Code\n",
    "\n",
    "```python\n",
    "from pyspark.sql.functions import col, to_timestamp, explode\n",
    "\n",
    "# Read Bronze layer\n",
    "df_bronze = spark.read.format(\"delta\").load(bronze_path)\n",
    "\n",
    "# Transform to Silver\n",
    "df_silver = df_bronze \\\n",
    "    .select(\n",
    "        col(\"id\").alias(\"document_id\"),\n",
    "        col(\"sourceFile\").alias(\"source_file\"),\n",
    "        to_timestamp(col(\"processedAt\")).alias(\"processed_at\"),\n",
    "        col(\"status\"),\n",
    "        col(\"modelId\").alias(\"model_id\"),\n",
    "        col(\"modelConfidence\").alias(\"model_confidence\"),\n",
    "        col(\"docType\").alias(\"document_type\"),\n",
    "        col(\"fields\"),\n",
    "        col(\"_ingested_at\")\n",
    "    ) \\\n",
    "    .withColumn(\"_is_valid\", col(\"status\") == \"completed\")\n",
    "\n",
    "# Write to Silver layer with partitioning\n",
    "silver_path = f\"abfss://delta@{storage_account}.dfs.core.windows.net/silver/documents/\"\n",
    "\n",
    "df_silver.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"status\", \"document_type\") \\\n",
    "    .save(silver_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "## 4. SQL Serverless Queries\n",
    "\n",
    "Query data using T-SQL without provisioning dedicated resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [],
   "source": [
    "# List SQL scripts in workspace\n",
    "Write-Host \"SQL scripts in workspace:\" -ForegroundColor Cyan\n",
    "\n",
    "az synapse sql-script list `\n",
    "    --workspace-name $SYNAPSE_WORKSPACE `\n",
    "    --query \"[].name\" `\n",
    "    --output table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "### Query Cosmos DB via SQL Serverless\n",
    "\n",
    "```sql\n",
    "-- Query Cosmos DB analytical store directly\n",
    "SELECT TOP 100\n",
    "    doc.id,\n",
    "    doc.sourceFile,\n",
    "    doc.processedAt,\n",
    "    doc.status,\n",
    "    doc.modelId,\n",
    "    doc.modelConfidence\n",
    "FROM OPENROWSET(\n",
    "    'CosmosDB',\n",
    "    'Account=your-cosmos-account;Database=DocumentsDB;Key=your-key',\n",
    "    ExtractedDocuments\n",
    ") WITH (\n",
    "    id VARCHAR(100),\n",
    "    sourceFile VARCHAR(500),\n",
    "    processedAt VARCHAR(50),\n",
    "    status VARCHAR(50),\n",
    "    modelId VARCHAR(100),\n",
    "    modelConfidence FLOAT\n",
    ") AS doc\n",
    "ORDER BY doc.processedAt DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "### Query Delta Lake via SQL Serverless\n",
    "\n",
    "```sql\n",
    "-- Query Silver Delta Lake layer\n",
    "SELECT \n",
    "    status,\n",
    "    document_type,\n",
    "    COUNT(*) as document_count,\n",
    "    AVG(model_confidence) as avg_confidence\n",
    "FROM OPENROWSET(\n",
    "    BULK 'https://your-storage.dfs.core.windows.net/delta/silver/documents/',\n",
    "    FORMAT = 'DELTA'\n",
    ") AS docs\n",
    "GROUP BY status, document_type\n",
    "ORDER BY document_count DESC;\n",
    "\n",
    "-- Time-based analysis\n",
    "SELECT \n",
    "    CAST(processed_at AS DATE) as process_date,\n",
    "    COUNT(*) as documents_processed,\n",
    "    SUM(CASE WHEN _is_valid = 1 THEN 1 ELSE 0 END) as successful\n",
    "FROM OPENROWSET(\n",
    "    BULK 'https://your-storage.dfs.core.windows.net/delta/silver/documents/',\n",
    "    FORMAT = 'DELTA'\n",
    ") AS docs\n",
    "WHERE processed_at > DATEADD(day, -30, GETDATE())\n",
    "GROUP BY CAST(processed_at AS DATE)\n",
    "ORDER BY process_date DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "## 5. Deploy Analytics Artifacts\n",
    "\n",
    "Deploy notebooks and SQL scripts to Synapse workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "pwsh"
    },
    "polyglot_notebook": {
     "kernelName": "pwsh"
    }
   },
   "outputs": [],
   "source": [
    "# Deploy all Synapse artifacts including notebooks and SQL scripts\n",
    "\n",
    "# Get the notebook directory and navigate to project root\n",
    "$notebookDir = (Get-Location).Path\n",
    "if ($notebookDir -match \"notebooks$\") {\n",
    "    $projectRoot = Split-Path $notebookDir -Parent\n",
    "} else {\n",
    "    # Assume we're already at project root or find it\n",
    "    $projectRoot = $notebookDir\n",
    "    while ($projectRoot -and -not (Test-Path (Join-Path $projectRoot \"scripts\"))) {\n",
    "        $projectRoot = Split-Path $projectRoot -Parent\n",
    "    }\n",
    "}\n",
    "\n",
    "$STORAGE_URL = \"https://$STORAGE_ACCOUNT.blob.core.windows.net\"\n",
    "$COSMOS_ENDPOINT = \"https://$COSMOS_ACCOUNT.documents.azure.com:443/\"\n",
    "\n",
    "Write-Host \"Deploying Synapse analytics artifacts...\" -ForegroundColor Cyan\n",
    "Write-Host \"  Synapse Workspace: $SYNAPSE_WORKSPACE (RG: $SYNAPSE_RESOURCE_GROUP)\" -ForegroundColor Gray\n",
    "Write-Host \"  Storage Account:   $STORAGE_ACCOUNT (RG: $STORAGE_RESOURCE_GROUP)\" -ForegroundColor Gray\n",
    "Write-Host \"  Cosmos DB Account: $COSMOS_ACCOUNT (RG: $COSMOS_RESOURCE_GROUP)\" -ForegroundColor Gray\n",
    "\n",
    "$scriptPath = Join-Path $projectRoot \"scripts\\Deploy-SynapseArtifacts.ps1\"\n",
    "\n",
    "if (Test-Path $scriptPath) {\n",
    "    & $scriptPath `\n",
    "        -WorkspaceName $SYNAPSE_WORKSPACE `\n",
    "        -ResourceGroup $SYNAPSE_RESOURCE_GROUP `\n",
    "        -DeploymentMode direct `\n",
    "        -StorageAccountUrl $STORAGE_URL `\n",
    "        -CosmosEndpoint $COSMOS_ENDPOINT\n",
    "} else {\n",
    "    Write-Host \"Script not found at: $scriptPath\" -ForegroundColor Red\n",
    "    Write-Host \"Run this from the project root or ensure scripts/Deploy-SynapseArtifacts.ps1 exists\" -ForegroundColor Yellow\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "## KQL Queries for Analytics\n",
    "\n",
    "Use KQL (Kusto Query Language) for advanced analytics in Synapse."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Sample KQL Query\n\nRun this in Synapse Studio KQL notebook (connected to your Data Explorer pool or external cluster):\n\n```kql\n// Document processing summary\ndocuments\n| summarize \n    TotalDocuments = count(),\n    SuccessCount = countif(status == \"completed\"),\n    FailureCount = countif(status == \"failed\"),\n    AvgConfidence = avg(modelConfidence)\n| extend SuccessRate = round(100.0 * SuccessCount / TotalDocuments, 2)\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "polyglot_notebook": {
     "kernelName": "markdown"
    }
   },
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Open Synapse Studio** - Access notebooks and SQL scripts\n",
    "2. **Create Spark Pool** - Required for running Spark notebooks\n",
    "3. **Set up monitoring** - See `07-Monitoring-Troubleshooting.ipynb`\n",
    "\n",
    "### Synapse Studio Links\n",
    "\n",
    "Open your Synapse Studio at: `https://web.azuresynapse.net/?workspace=%2fsubscriptions%2f{subscription_id}%2fresourceGroups%2f{resource_group}%2fproviders%2fMicrosoft.Synapse%2fworkspaces%2f{workspace_name}`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (PowerShell)",
   "language": "PowerShell",
   "name": ".net-pwsh"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "pwsh",
    "items": [
     {
      "aliases": [],
      "languageName": "kql",
      "name": "kql"
     },
     {
      "aliases": [],
      "languageName": "markdown",
      "name": "markdown"
     },
     {
      "aliases": [],
      "languageName": "pwsh",
      "name": "pwsh"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}